from bs4 import BeautifulSoup
from selenium import webdriver
import json
exercises = [(u'3/4 SIT-UP', u'http://www.bodybuilding.com/exercises/detail/view/name/34-sit-up')] #from last script

class WO():
    def __init__(self, url=""):
        self.browser = webdriver.Chrome()
        self.url = url
    def close_out(self):
        self.browser.close()
    def get_info(self, n):
        self.browser.get(self.url)
        elements = self.browser.find_elements_by_xpath("//div[@id='exerciseDetails']/p")
        element = elements[-n]
        info = element.text.split('\n')
        infodict = {}
        for x in info:
            a, b = x.split(':')
            infodict[a] = b
        pl = self.browser.find_element_by_xpath("//div[@class='photoLeft']/a").get_attribute('href')
        pr = self.browser.find_element_by_xpath("//div[@class='photoLeft']/a").get_attribute('href')
        guide  = self.browser.find_elements_by_xpath("//div[@class='guideContent']/ol/li")
        infodict['guide'] = [x.text for x in guide]
        infodict['pic_left'] = pl
        infodict['pic_right'] = pr

        return infodict
        
data_ditct = {'type','main_muscle','equipment','mechanics', 'level', 'sport', 'force'}
allofit = []
start = 0

w = WO()

for stuff in exercises[1:]:
    start +=1
    print (start)
    print (stuff[1])
    i = {}

    try:
        w.url = stuff[1]
        i = w.get_info(2)
        i['link'] = stuff[1]
        a = {stuff[0]:i}
        allofit.append(a)

        print (i)
    except Exception as e:
        print ("re-trying with second p")
        try:
            w.url = stuff[1]
            i = w.get_info(1)
            i['link'] = stuff[1]
            a = {stuff[0]:i}
            allofit.append(a)
            w.close_out()
            print (i)
        except Exception as e:
            print ("second try failed")
            print (e)
            pass

w.close_out()
with open('output_2_main.json', 'w') as outfile:
	json.dump(allofit, outfile)